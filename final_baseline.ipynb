{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions.CreatingNewDataframe as CreatingNewDataframe\n",
    "import functions.GenerateFis as Features\n",
    "import functions.GenerateMeansWithOffset as MeansOffset\n",
    "\n",
    "\n",
    "from functions.date_split import split_month_test\n",
    "from score_submission import our_scorer, scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = pd.read_csv('train.csv.zip', parse_dates=['DATE'])\n",
    "ids = np.unique(df_initial.ATM_ID)\n",
    "np.random.shuffle(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means = MeansOffset.CreateColumnsOfMeans(df_initial, window=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparatingAtmIds(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract the subject & body from a usenet post in a single pass.\n",
    "\n",
    "    Takes a sequence of strings and produces a dict of sequences.  Keys are\n",
    "    `subject` and `body`.\n",
    "    \"\"\"\n",
    "    def fit(self, x, y=None):\n",
    "        self.train = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.train:\n",
    "            print(\"TRAIN ONLY CALLED\")\n",
    "            print(\"Separating finished\")\n",
    "            return CreatingNewDataframe.CleanDataFrame_TRAIN_ONLY(df=X, window_size=15)\n",
    "        else:\n",
    "            print(\"TEST ONLY CALLED\")\n",
    "            print(\"Separating finished\")\n",
    "            return CreatingNewDataframe.CleanDataFrame_TEST(df=X, window_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalStepForSubmission(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    FINAL\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X[['DATE', \"ATM_ID\", \"y_predict\"]]\n",
    "        X.columns = ['DATE', \"ATM_ID\", \"CLIENT_OUT\"]\n",
    "        print(len(np.unique(X.ATM_ID)))\n",
    "        print(\"FinalStepForSubmission Finished\")\n",
    "        return X\n",
    "        \n",
    "class WrapperForEstimator(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    FINAL\n",
    "    \"\"\"\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        indices_without_nan = X.isnull().any(axis=1)\n",
    "        indices_without_nan = X.index[indices_without_nan]\n",
    "        \n",
    "        X.drop(axis=0, index=indices_without_nan, inplace=True)\n",
    "        y.drop(axis=0, index=indices_without_nan, inplace=True)\n",
    "        \n",
    "        print(\"WrapperForEstimator fit called\")\n",
    "        print(X.columns)\n",
    "        \n",
    "        self.estimator.fit(X.drop(['DATE',  'ATM_ID', 'CLIENT_OUT'], axis=1, inplace=False),\n",
    "                           y)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(\"WrapperForEstimator transform called\")\n",
    "        \n",
    "        y_pred = self.estimator.predict(X.drop(['DATE',  'ATM_ID', 'CLIENT_OUT'], axis=1, inplace=False))\n",
    "        \n",
    "        X_tr = X.copy()\n",
    "        X_tr['y_predict'] = y_pred\n",
    "        print(\"Transform from estimator Finished\")\n",
    "        return X_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_initial\n",
    "y = df_initial[['CLIENT_OUT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-aed748541c30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dates to predict\n",
    "pred_dates  = ['2017-08-16', '2017-08-17', '2017-08-18', '2017-08-19',\n",
    "               '2017-08-20', '2017-08-21', '2017-08-22', '2017-08-23',\n",
    "               '2017-08-24', '2017-08-25', '2017-08-26', '2017-08-27',\n",
    "               '2017-08-28', '2017-08-29', '2017-08-30', '2017-08-31',\n",
    "               '2017-09-01', '2017-09-02', '2017-09-03', '2017-09-04',\n",
    "               '2017-09-05', '2017-09-06', '2017-09-07', '2017-09-08',\n",
    "               '2017-09-09', '2017-09-10', '2017-09-11', '2017-09-12',\n",
    "               '2017-09-13', '2017-09-14', '2017-09-15', '2017-09-16',\n",
    "               '2017-09-17']\n",
    "\n",
    "rows = []\n",
    "\n",
    "\n",
    "\n",
    "for id in ids:\n",
    "    mean = 0\n",
    "#     df[df.ATM_ID==id].CLIENT_OUT.mean()\n",
    "    for date in pred_dates:\n",
    "        rows.append((date, id, mean))\n",
    "submission = pd.DataFrame(rows, columns = ['DATE', 'ATM_ID', 'CLIENT_OUT'])\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(rows, columns = ['DATE', 'ATM_ID', 'CLIENT_OUT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_scores = cross_val_score(pipeline, X, y, scoring=our_scorer,  groups=X['ATM_ID'].values, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FlattenList(l_of_l):\n",
    "    return np.array([x for sublist in l_of_l for x in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FlattenList([[x, x+1, x+2, x+3, x+4, x+5, x+6] for x in range(0, 100, 33)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = split_month_test(df_initial,\n",
    "                                    test_days=33,\n",
    "                                     train_days=0,\n",
    "                                     unuseddays_in_end=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"rfc\", WrapperForEstimator(RandomForestRegressor(n_jobs=-1))), #predict step\n",
    "    (\"submission\", FinalStepForSubmission()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateScore(pipelines, df=df_initial):\n",
    "    test_days = 33\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for unuseddays_in_end in range(0, 28, 28):\n",
    "        train_df, test_df = split_month_test(df,\n",
    "                                             test_days=test_days,\n",
    "                                             train_days=0,\n",
    "                                             unuseddays_in_end=unuseddays_in_end)\n",
    "        \n",
    "        y_test = test_df['CLIENT_OUT']\n",
    "        test_df['CLIENT_OUT'] = None\n",
    "        \n",
    "        DF_FOR_FEATURES = pd.merge([train_df, test_df], axis=0)\n",
    "        \n",
    "        df1, df2, df3, df4, df5 = AddFeatures(DF_FOR_FEATURES)\n",
    "\n",
    "\n",
    "        end_of_train = train_df.shape[0]\n",
    "        \n",
    "        \n",
    "        df_train_1 = df1[:end_of_train]\n",
    "        df_train_2 = df2[:end_of_train]\n",
    "        df_train_3 = df3[:end_of_train]\n",
    "        df_train_4 = df4[:end_of_train]\n",
    "        df_train_5 = df5[:end_of_train]\n",
    "        df_trains = [df_train_1, df_train_2, df_train_3, df_train_4, df_train_5]\n",
    "        \n",
    "        indices = FlattenList([[x, x+1, x+2, x+3, x+4, x+5, x+6] for x\n",
    "                            in range(0, test_df.shape[0], test_days)]) + end_of_train\n",
    "        df_test_1 = df1[indices]\n",
    "        y_test_1 = y_test[indices]\n",
    "        \n",
    "        indices = FlattenList([[x, x+1, x+2, x+3, x+4, x+5, x+6] for x\n",
    "                            in range(7, test_df.shape[0], test_days)]) + end_of_train\n",
    "        \n",
    "        df_test_2 = df2[indices]\n",
    "        y_test_2 = y_test[indices]\n",
    "        \n",
    "        indices = FlattenList([[x, x+1, x+2, x+3, x+4, x+5, x+6] for x\n",
    "                            in range(14, test_df.shape[0], test_days)]) + end_of_train\n",
    "        \n",
    "        df_test_3 = df3[indices]\n",
    "        y_test_3 = y_test[indices]        \n",
    "        \n",
    "        indices = FlattenList([[x, x+1, x+2, x+3, x+4, x+5, x+6] for x\n",
    "                            in range(21, test_df.shape[0], test_days)]) + end_of_train\n",
    "        \n",
    "        df_test_4 = df4[indices]\n",
    "        y_test_4 = y_test[indices]        \n",
    "        \n",
    "        indices = FlattenList([[x, x+1, x+2, x+3, x+4, ] for x\n",
    "                            in range(28, test_df.shape[0], test_days)]) + end_of_train\n",
    "        \n",
    "        df_test_5 = df5[indices]\n",
    "        y_test_5 = y_test[indices]\n",
    "        \n",
    "        \n",
    "        df_tests = [df_test_1, df_test_2, df_test_3, df_test_4, df_test_5]\n",
    "        y_tests = [y_test_1, y_test_2, y_test_3, y_test_4, y_test_5]\n",
    "    \n",
    "        \n",
    "        y_preds = []\n",
    "        for i in range(5):\n",
    "            pipelines[i].fit(df_trains[i], PUT Y HERE)\n",
    "            y_pred = models[i].predict(df_tests[i])            \n",
    "            y_preds.append(y_pred)\n",
    "            \n",
    "        \n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array([283, 371, 209,  10, 319, 311, 276, 138,   6, 245, 327,  69, 302,\n",
    "        55, 257, 305, 403, 291, 203, 231,  92, 142, 343, 345, 127,  52,\n",
    "       389, 413, 217, 328,  23, 230,  41,  30, 299, 154,   8, 105,  56,\n",
    "        87, 108,  90, 396,  72,  91,  76, 321, 315, 140, 317, 255, 194,\n",
    "       330,  89, 415, 385, 113, 107, 272,  31, 318,  71,   7, 262, 243,\n",
    "        36,  28, 357,  68, 264, 136, 167, 316, 273, 172, 390,  96,  98,\n",
    "        79, 401, 228, 212,  25, 163,  93, 147, 151,  86,  21,  11, 274,\n",
    "       119,  81, 309,  47,  22, 252, 199, 380,  80, 314,  82,  38, 258,\n",
    "       370, 310, 189,  24, 256, 112, 177, 367, 100, 342, 339, 149, 196,\n",
    "       406, 277, 286,  67, 242, 260, 235, 186, 352,  48, 166, 275, 391,\n",
    "       182, 141, 238, 150, 383, 376, 213, 246, 249,   3, 148, 193, 248,\n",
    "       155, 290, 362, 168,  88,  35,  97, 374, 131, 307, 219, 387, 340,\n",
    "       306,  78, 278,  99, 297, 220,  17,  44,  34, 192, 394, 354, 240,\n",
    "        63, 111, 288, 341,  51, 103, 338, 181,  32, 407, 191, 280,   0,\n",
    "       373, 378, 117, 361, 355, 241, 115,  45,  73, 207, 326, 282, 336,\n",
    "        14, 414, 372,  33, 303,   5, 160,  40, 284, 226, 289, 395, 185,\n",
    "        74, 180, 169, 404,   9,  84, 369,  77,  54, 386, 216,  50, 161,\n",
    "       381, 300, 211,  29, 366, 139,  95, 287, 295,  49, 331, 405, 360,\n",
    "       279,  19,  57, 109, 368, 312, 379, 281, 225,  53, 301, 195, 270,\n",
    "       304, 347,   4, 128,  65, 178,   2, 176, 126,  60,  94, 285,  43,\n",
    "       106,  64, 334,  18, 102, 233, 408, 179, 399, 337,  66,  61, 244,\n",
    "       269, 418, 265, 239,  70,  58, 324, 348,  27, 222, 382, 271, 359,\n",
    "       205, 173, 208, 116, 101, 298, 159, 419,  26, 267,  85, 129, 375,\n",
    "       123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#         train_df1, test_df1 = split_month_test(df1,\n",
    "#                                      test_days=test_days,\n",
    "#                                      train_days=0,\n",
    "#                                      unuseddays_in_end=unuseddays_in_end)\n",
    "        \n",
    "#         train_df2, test_df2 = split_month_test(df2,\n",
    "#                                      test_days=test_days,\n",
    "#                                      train_days=0,\n",
    "#                                      unuseddays_in_end=unuseddays_in_end)\n",
    "\n",
    "#         train_df3, test_df3 = split_month_test(df3,\n",
    "#                                      test_days=test_days,\n",
    "#                                      train_days=0,\n",
    "#                                      unuseddays_in_end=unuseddays_in_end)\n",
    "\n",
    "#         train_df4, test_df4 = split_month_test(df4,\n",
    "#                                      test_days=test_days,\n",
    "#                                      train_days=0,\n",
    "#                                      unuseddays_in_end=unuseddays_in_end)\n",
    "\n",
    "#         train_df5, test_df5 = split_month_test(df5,\n",
    "#                                      test_days=test_days,\n",
    "#                                      train_days=0,\n",
    "#                                      unuseddays_in_end=unuseddays_in_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
